{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JAbzFv2sz1JC"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_block(num_channels):\n",
        "  return nn.Sequential(\n",
        "      nn.LazyBatchNorm2d(),nn.ReLU(),\n",
        "      nn.LazyConv2d(num_channels,kernel_size=3,padding=1)\n",
        "  )"
      ],
      "metadata": {
        "id": "6GPsSggO00ux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DenseBlock(nn.Module):\n",
        "  def __init__(self,num_convs,num_channels):\n",
        "    \"\"\"\n",
        "    num_convs: it is the number of blocks we want\n",
        "    num_channels: growth rate, it is the k.\n",
        "    \"\"\"\n",
        "    super(DenseBlock,self).__init__()\n",
        "    layer = []\n",
        "    for i in range(num_convs):\n",
        "      layer.append(conv_block(num_channels=num_channels))\n",
        "    self.net = nn.Sequential(*layer)\n",
        "\n",
        "  def forward(self,X):\n",
        "    for blk in self.net:\n",
        "      Y = blk(X)\n",
        "      # concatenate input and output of each block along the channels\n",
        "      X = torch.cat((X,Y),dim=1)\n",
        "    return X"
      ],
      "metadata": {
        "id": "I9UX69uB1JiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transition_block(num_channels):\n",
        "  return nn.Sequential(\n",
        "      nn.LazyBatchNorm2d(),nn.ReLU(),\n",
        "      nn.LazyConv2d(num_channels,kernel_size=1),\n",
        "      nn.AvgPool2d(kernel_size=2,stride=2)\n",
        "  )"
      ],
      "metadata": {
        "id": "pzLc-j4g2sol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DenseNet(nn.Module):\n",
        "\n",
        "  def __init__(self,num_channels=64,growth_rate=32,arch=(4,4,4,4),num_classes=10):\n",
        "    super(DenseNet, self).__init__()\n",
        "    self.net = nn.Sequential(self.block1())\n",
        "    for i, num_convs in enumerate(arch):\n",
        "      self.net.add_module(f\"dense_blk{i+1}\",DenseBlock(num_convs,growth_rate))\n",
        "      # num_channels += num_convs*growth_rate\n",
        "\n",
        "      # if i != len(arch)-1:\n",
        "      #   num_channels//=2\n",
        "      #   self.net.add_module(f\"tran_blk{i+1}\",transition_block(num_channels))\n",
        "    self.net.add_module('last', nn.Sequential(\n",
        "        nn.LazyBatchNorm2d(), nn.ReLU(),\n",
        "        nn.AdaptiveAvgPool2d((1, 1)), nn.Flatten(),\n",
        "        nn.LazyLinear(num_classes)))\n",
        "  def block1(self):\n",
        "    return nn.Sequential(\n",
        "        nn.LazyConv2d(64,kernel_size=7,stride=2,padding=3),\n",
        "        nn.LazyBatchNorm2d(), nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n",
        "    )\n",
        "  def forward(self,X):\n",
        "    return self.net(X)"
      ],
      "metadata": {
        "id": "5yPqAING4DsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "oxrQmdUO9Bj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((96,96)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0,),(1,))\n",
        "])"
      ],
      "metadata": {
        "id": "1o3wCUua9_F0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = MNIST(root=\"./root\",train=True,transform=transform,download=True)\n",
        "train_loader = DataLoader(train_data,64,shuffle=True)"
      ],
      "metadata": {
        "id": "wQ72Fgla-PI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = MNIST(root=\"./root\",train=False,transform=transform,download=True)\n",
        "test_loader = DataLoader(test_data,64,shuffle=True)"
      ],
      "metadata": {
        "id": "LIVPJZSn-8ob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "53yprhRi_X6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6061ea08"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training_loop(model, loss_fn, optimizer, epochs, loader):\n",
        "    model.train()\n",
        "    for ep in range(epochs):\n",
        "        for feature, target in loader:\n",
        "            feature, target = feature.to(device), target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            y_pred = model(feature)\n",
        "            loss = loss_fn(y_pred, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        print(f\"Epoch {ep+1}, loss: {loss.item()}\")\n",
        "\n",
        "def testing_loop(model, loss_fn, loader):\n",
        "    model.eval() # Set the model to evaluation mode\n",
        "    with torch.no_grad():\n",
        "        for feature, target in loader:\n",
        "            feature, target = feature.to(device), target.to(device)\n",
        "            prediction = model(feature)\n",
        "            loss = loss_fn(prediction, target)\n",
        "        print(f\"Test loss: {loss.item()}\")"
      ],
      "metadata": {
        "id": "OKW7UtsT_MyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = DenseNet()\n",
        "model.to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(),lr = 1e-4)\n",
        "training_loop(model,loss_fn,optimizer,10,train_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuyuh0iuAxjW",
        "outputId": "77541daf-6927-4745-cdab-863b02bcc7b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, loss: 0.1086050346493721\n",
            "Epoch 2, loss: 0.07311496138572693\n",
            "Epoch 3, loss: 0.2029210478067398\n",
            "Epoch 4, loss: 0.0790981650352478\n",
            "Epoch 5, loss: 0.028374947607517242\n",
            "Epoch 6, loss: 0.02086241915822029\n",
            "Epoch 7, loss: 0.08081139624118805\n",
            "Epoch 8, loss: 0.03718626871705055\n",
            "Epoch 9, loss: 0.009528332389891148\n",
            "Epoch 10, loss: 0.007580135948956013\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testing_loop(model,loss_fn,test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nM8j2OxWBUYN",
        "outputId": "85380b3f-a1f1-445c-bc0d-fb2d8ba21dec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.0008846366545185447\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for feature, target in test_loader:\n",
        "        feature, target = feature.to(device), target.to(device)\n",
        "        prediction = model(feature)\n",
        "        loss = loss_fn(prediction, target)\n",
        "        _, predicted = torch.max(prediction.data, 1)\n",
        "        total += target.size(0)\n",
        "        correct += (predicted == target).sum().item()\n",
        "\n",
        "print(f\"Test Loss: {loss.item():.4f}\")\n",
        "print(f\"Accuracy: {100 * correct / total:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfPiCwDzBhWN",
        "outputId": "ba46f9d8-9ccb-481c-c8c1-a9c36ede7d70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0142\n",
            "Accuracy: 99.16%\n"
          ]
        }
      ]
    }
  ]
}